|Basic Memory Usage: 8.69MB current, 8.69MB max
====================================================================================================
    - data : ../data/penn/
    - dataset : ptb
    - n_layer : 40
    - d_embed : 400
    - nhid : 1000
    - nout : 400
    - epochs : 500
    - halt_ppl : None
    - time_limit : 16000.0
    - optim : Adam
    - lr : 0.01
    - clip : 0.225
    - batch_size : 32
    - batch_chunk : 1
    - seq_len : 110
    - subseq_len : 55
    - dropout : 0.45
    - dropouti : 0.45
    - wdrop : 0.5
    - emb_dropout : 0.1
    - dropouth : 0.28
    - weight_decay : 1.2e-06
    - wnorm : True
    - seed : 100
    - cuda : True
    - not_tied : False
    - anneal : 10
    - log_interval : 100
    - when : [-1]
    - ksize : 2
    - dilation : 1
    - n_experts : 0
    - multi_gpu : False
    - use_gpus : None
    - f_thres : 45
    - b_thres : 45
    - work_dir : LM-TREdeq-ptb/20210507-171659
    - restart : False
    - restart_dir : 
    - debug : False
    - gpu0_bsz : 7
    - pretrain_steps : 0
    - start_train_steps : 0
    - timing : True
    - eval_mem : False
    - eval : False
    - load : 
    - name : deq_1
    - tied : True
    - n_token : 10000
    - n_all_param : 24193603
====================================================================================================
#params = 24193603
|Static Memory Usage: 252.25MB current, 269.03MB max
| epoch   1 step      100 |    100 batches | lr 0.01 | ms/batch 2853.75 | loss  6.47 | ppl   643.366
| epoch   1 step      200 |    200 batches | lr 0.01 | ms/batch 3020.87 | loss  5.79 | ppl   328.229
----------------------------------------------------------------------------------------------------
| Eval   1 at step      265 | time: 858.18s | valid loss  5.37 | valid ppl   214.161
| Total time: 856.38s
----------------------------------------------------------------------------------------------------
| epoch   2 step      300 |     35 batches | lr 0.01 | ms/batch 3783.36 | loss  1.96 | ppl     7.108
| epoch   2 step      400 |    135 batches | lr 0.01 | ms/batch 3021.24 | loss  5.48 | ppl   240.549
| epoch   2 step      500 |    235 batches | lr 0.01 | ms/batch 3021.68 | loss  5.36 | ppl   213.391
----------------------------------------------------------------------------------------------------
| Eval   2 at step      530 | time: 877.35s | valid loss  5.10 | valid ppl   164.405
| Total time: 1733.33s
----------------------------------------------------------------------------------------------------
| epoch   3 step      600 |     70 batches | lr 0.01 | ms/batch 3791.48 | loss  3.71 | ppl    40.956
| epoch   3 step      700 |    170 batches | lr 0.01 | ms/batch 3022.18 | loss  5.25 | ppl   189.694
----------------------------------------------------------------------------------------------------
| Eval   3 at step      795 | time: 877.54s | valid loss  4.96 | valid ppl   142.152
| Total time: 2610.65s
----------------------------------------------------------------------------------------------------
| epoch   4 step      800 |      5 batches | lr 0.01 | ms/batch 3789.49 | loss  0.27 | ppl     1.309
| epoch   4 step      900 |    105 batches | lr 0.01 | ms/batch 3014.55 | loss  5.29 | ppl   198.268
| epoch   4 step     1000 |    205 batches | lr 0.01 | ms/batch 3011.67 | loss  5.26 | ppl   192.818
----------------------------------------------------------------------------------------------------
| Eval   4 at step     1060 | time: 874.99s | valid loss  5.04 | valid ppl   155.101
| Total time: 3485.36s
----------------------------------------------------------------------------------------------------
| epoch   5 step     1100 |     40 batches | lr 0.01 | ms/batch 3755.58 | loss  2.11 | ppl     8.214
| epoch   5 step     1200 |    140 batches | lr 0.01 | ms/batch 3013.99 | loss  5.21 | ppl   183.470
| epoch   5 step     1300 |    240 batches | lr 0.01 | ms/batch 3015.10 | loss  5.09 | ppl   162.624
----------------------------------------------------------------------------------------------------
| Eval   5 at step     1325 | time: 873.07s | valid loss  4.88 | valid ppl   131.899
| Total time: 4358.66s
----------------------------------------------------------------------------------------------------
| epoch   6 step     1400 |     75 batches | lr 0.01 | ms/batch 3780.35 | loss  3.82 | ppl    45.447
| epoch   6 step     1500 |    175 batches | lr 0.01 | ms/batch 3016.79 | loss  5.04 | ppl   153.900
----------------------------------------------------------------------------------------------------
| Eval   6 at step     1590 | time: 876.26s | valid loss  4.81 | valid ppl   122.337
| Total time: 5234.30s
----------------------------------------------------------------------------------------------------
| epoch   7 step     1600 |     10 batches | lr 0.01 | ms/batch 3781.58 | loss  0.52 | ppl     1.678
| epoch   7 step     1700 |    110 batches | lr 0.01 | ms/batch 3017.65 | loss  5.00 | ppl   148.391
| epoch   7 step     1800 |    210 batches | lr 0.01 | ms/batch 3017.97 | loss  4.94 | ppl   140.382
----------------------------------------------------------------------------------------------------
| Eval   7 at step     1855 | time: 875.87s | valid loss  4.77 | valid ppl   117.856
| Total time: 6109.95s
----------------------------------------------------------------------------------------------------
| epoch   8 step     1900 |     45 batches | lr 0.01 | ms/batch 3778.69 | loss  2.24 | ppl     9.414
| epoch   8 step     2000 |    145 batches | lr 0.01 | ms/batch 3016.89 | loss  4.94 | ppl   139.652
| epoch   8 step     2100 |    245 batches | lr 0.01 | ms/batch 3017.00 | loss  4.88 | ppl   132.119
----------------------------------------------------------------------------------------------------
| Eval   8 at step     2120 | time: 875.57s | valid loss  4.74 | valid ppl   114.414
| Total time: 6985.30s
----------------------------------------------------------------------------------------------------
| epoch   9 step     2200 |     80 batches | lr 0.01 | ms/batch 3780.11 | loss  3.93 | ppl    51.097
| epoch   9 step     2300 |    180 batches | lr 0.01 | ms/batch 3018.37 | loss  4.87 | ppl   130.215
----------------------------------------------------------------------------------------------------
| Eval   9 at step     2385 | time: 876.00s | valid loss  4.73 | valid ppl   112.805
| Total time: 7861.07s
----------------------------------------------------------------------------------------------------
| epoch  10 step     2400 |     15 batches | lr 0.01 | ms/batch 3779.13 | loss  0.74 | ppl     2.097
| epoch  10 step     2500 |    115 batches | lr 0.01 | ms/batch 3018.10 | loss  4.87 | ppl   130.116
| epoch  10 step     2600 |    215 batches | lr 0.01 | ms/batch 3017.97 | loss  4.81 | ppl   122.494
----------------------------------------------------------------------------------------------------
| Eval  10 at step     2650 | time: 876.25s | valid loss  4.70 | valid ppl   110.104
| Total time: 8737.06s
----------------------------------------------------------------------------------------------------
| epoch  11 step     2700 |     50 batches | lr 0.01 | ms/batch 3782.74 | loss  2.43 | ppl    11.322
| epoch  11 step     2800 |    150 batches | lr 0.01 | ms/batch 3017.82 | loss  4.83 | ppl   125.080
| epoch  11 step     2900 |    250 batches | lr 0.01 | ms/batch 3017.71 | loss  4.78 | ppl   119.622
----------------------------------------------------------------------------------------------------
| Eval  11 at step     2915 | time: 875.96s | valid loss  4.68 | valid ppl   107.710
| Total time: 9612.81s
----------------------------------------------------------------------------------------------------
| epoch  12 step     3000 |     85 batches | lr 0.01 | ms/batch 3780.32 | loss  4.08 | ppl    59.369
| epoch  12 step     3100 |    185 batches | lr 0.01 | ms/batch 3017.76 | loss  4.78 | ppl   118.653
----------------------------------------------------------------------------------------------------
| Eval  12 at step     3180 | time: 875.92s | valid loss  4.67 | valid ppl   106.226
| Total time: 10488.40s
----------------------------------------------------------------------------------------------------
| epoch  13 step     3200 |     20 batches | lr 0.01 | ms/batch 3780.71 | loss  0.97 | ppl     2.634
| epoch  13 step     3300 |    120 batches | lr 0.01 | ms/batch 3017.91 | loss  4.79 | ppl   120.540
| epoch  13 step     3400 |    220 batches | lr 0.01 | ms/batch 3017.73 | loss  4.72 | ppl   112.210
----------------------------------------------------------------------------------------------------
| Eval  13 at step     3445 | time: 875.99s | valid loss  4.65 | valid ppl   105.035
| Total time: 11364.20s
----------------------------------------------------------------------------------------------------
| epoch  14 step     3500 |     55 batches | lr 0.01 | ms/batch 3783.17 | loss  2.62 | ppl    13.732
| epoch  14 step     3600 |    155 batches | lr 0.01 | ms/batch 3017.43 | loss  4.76 | ppl   117.294
| epoch  14 step     3700 |    255 batches | lr 0.01 | ms/batch 3017.68 | loss  4.72 | ppl   111.991
----------------------------------------------------------------------------------------------------
| Eval  14 at step     3710 | time: 876.52s | valid loss  4.64 | valid ppl   103.179
| Total time: 12240.30s
----------------------------------------------------------------------------------------------------
| epoch  15 step     3800 |     90 batches | lr 0.01 | ms/batch 3788.71 | loss  4.28 | ppl    72.287
| epoch  15 step     3900 |    190 batches | lr 0.01 | ms/batch 3017.75 | loss  4.70 | ppl   109.485
----------------------------------------------------------------------------------------------------
| Eval  15 at step     3975 | time: 876.65s | valid loss  4.63 | valid ppl   102.712
| Total time: 13116.75s
----------------------------------------------------------------------------------------------------
| epoch  16 step     4000 |     25 batches | lr 0.01 | ms/batch 3783.07 | loss  1.19 | ppl     3.273
| epoch  16 step     4100 |    125 batches | lr 0.01 | ms/batch 3017.12 | loss  4.75 | ppl   115.275
| epoch  16 step     4200 |    225 batches | lr 0.01 | ms/batch 3016.79 | loss  4.67 | ppl   106.674
----------------------------------------------------------------------------------------------------
| Eval  16 at step     4240 | time: 875.95s | valid loss  4.63 | valid ppl   102.798
| Total time: 13992.25s
----------------------------------------------------------------------------------------------------
| epoch  17 step     4300 |     60 batches | lr 0.01 | ms/batch 3760.83 | loss  2.83 | ppl    16.874
| epoch  17 step     4400 |    160 batches | lr 0.01 | ms/batch 3017.92 | loss  4.72 | ppl   112.522
| epoch  17 step     4500 |    260 batches | lr 0.01 | ms/batch 3017.43 | loss  4.68 | ppl   107.248
----------------------------------------------------------------------------------------------------
| Eval  17 at step     4505 | time: 873.99s | valid loss  4.63 | valid ppl   102.440
| Total time: 14866.50s
----------------------------------------------------------------------------------------------------
| epoch  18 step     4600 |     95 batches | lr 0.01 | ms/batch 3779.21 | loss  4.48 | ppl    88.321
| epoch  18 step     4700 |    195 batches | lr 0.01 | ms/batch 3017.10 | loss  4.65 | ppl   104.423
----------------------------------------------------------------------------------------------------
| Eval  18 at step     4770 | time: 875.76s | valid loss  4.63 | valid ppl   102.011
| Total time: 15742.02s
----------------------------------------------------------------------------------------------------
| epoch  19 step     4800 |     30 batches | lr 0.01 | ms/batch 3778.78 | loss  1.41 | ppl     4.113
| epoch  19 step     4900 |    130 batches | lr 0.01 | ms/batch 3017.58 | loss  4.69 | ppl   108.920
| epoch  19 step     5000 |    230 batches | lr 0.01 | ms/batch 3017.06 | loss  4.64 | ppl   103.601
----------------------------------------------------------------------------------------------------
| Eval  19 at step     5035 | time: 875.96s | valid loss  4.62 | valid ppl   101.075
| Total time: 16617.73s
----------------------------------------------------------------------------------------------------
====================================================================================================
| End of training | test loss  4.58 | test ppl    97.204
| Maximum memory usage: 5566.31MB
====================================================================================================
